# Remote-Controlled-Robot-Car-using-PoseNet
This is a project to control a robotic car using human poses in real time. PoseNet is an ml5.js model that estimates human poses. It does this by tracking 34 different points on the human body and returning their x and y corrdinates in pixels. I have used this model to to train my own neural network to recognize 5 different poses and return a unique letter in the case of each pose. This letter is then communicated to an arduino over serial and to a different arduino using two hc-05 bluetooth modules that were paired using AT commands. The arduino with the slave bluetooth module drives the car, while the one with the master module is connected to the computer. Below are the steps to completing this project:

Setting up the arduinos (x2) and bluetooth modules (HC-05 x2):
1. Upload the hc-05_AT_MODE code to the arduino, then wire up the hc-05 to the arduino using the hc-05 setup fritzing diagram for guidance. Before connecting the 5V pin to the vcc pin on the module, press the button on the bluetooth module and let it go only when you have connecte the wires and you see slow blinking. Remember to do this for the 2nd module when you hook it up too. Bear in mind this only needs to be done for this step and not for normal wiring. Open up the serial monitor to fetch the address of the bluetooth module using the following commands. First, however, make sure the baud rate in the serial monitor is set to 9600 and that you are in Both NL & CR mode. Now we will fetch information for this module which we have chosen to be the slave module. In the serial monitor enter "AT" and you should get the following message: OK. "AT+UART?" returns the baud rate. "AT+ROLE?" which should return "+ROLE=0" signifying that this module is in slave mode. TO get the address, input "AT+ADDR?" and write the address somewhere because you will need it in the next step. Unplug this module and plug in your 2nd bluetooth module using the same setup. Proceed with the same steps, opening the serial moniteor and trying the commands, "AT" and "AT+UART?" to check you are getting good responses. Next, by typing “AT+ROLE=1” we will set the Bluetooth module as a master device. After this using the “AT+CMODE=0” we will set the connect mode to “fixed address” and using the “AT+BIND=” command we will set the address of the slave device that we previously wrote down.
2. Using the hc-05 setup diagram, connect an arduino to the slave module, then upload the arduino_comp code to it. Wire up the 2nd arduino using the car fritizng diagram and upload the arduino_car code to it. 

Training the Network and Controlling the Car:
1. Navigate to the sketch in this link: https://editor.p5js.org/amro.halwah/sketches/ez_jiVsq8. The data collection sketch is used to collect the data that we will use to train the model. Decide which poses you would like your model to recognize, and take the number of these poses and edit line 44 to reflect that. My number of outputs is 5 because I trained it to recognize 5 different poses for my project, but for your project this may vary so adjust it to the number you desire. Run the sketch. Input a string into the textbox and press enter, then walk back to stand in full view of the camera (you are given 5 seconds after pressing enter before the program starts collecting data of you position on the screen). When the program starts collecting data, it will be logged in the console that it is collecting and after 10 seconds it will inform you that it is not collecting. For these 10 seconds hold that pose infront of the camera and move around to introduce a diverse set of points for training your model. You do this for the number of outputs you selected in line 44 of the code, and when you are done type 'save' without the quotations and press enter. A json file will download to your computer, reanme it to data.json and you are ready to train your model.
2. Navigate to the sketch in this link: https://editor.p5js.org/amro.halwah/sketches/X6HdaKiDU. The model training sketch uses the data file to train your model, giving you 3 files that contain the necessary information for the model to predict your poses. These files include the weights and the number of layers within the neural network. Change the outputs in line 7 of the sketch to the number of putputs you selected in step 1, in line 44. Underneath the run button is a grey square button with an arrow, press that. You will see a menu, next to sketch files, expand the down arrow and select upload file. Upload your 'data.json' file and make sure the one already there has been deleted, then run the code. This will train your model and the graph to the right should show the loss decreasing over epochs. When the training is complete, 3 files will download. Make sure the naming convention is as follows => 'model.json', 'model_meta.json', and 'model.weights.bin'.
3. Navigate to the sketch in this link: https://editor.p5js.org/amro.halwah/sketches/DO4FQqy9P. Delete the files in the model folder under sketch files and upload the three files obtained from the last step in that folder. Update line 26 in your current sketch to reflect the number of outputs you have, should be the same number you picked in step 1 for line 44. Do not run the sketch yet.
4. To download the p5.serialcontrol application, navigate to the following link: https://github.com/p5-serial/p5.serialcontrol/releases. After pressing the link, navigate to ‘Assets’ under Beta 1.2 and download the zip file for your operating system. Unzip the folder and open the p5.serialcontrol application. Scan the ports then select the port that the arduino is connected to and open that. If you are unsure about the port you can use the arduino ide to find out. Simply go to tools, port, then you should be able to tell which port the arduino is connected to. Note the name of the port and copy that name. Paste that name on line 11 of the sketch in place of COM6.
5. You can run the code from step 3 and based on your pose, the model you trained will predict a string and display that on screen, as well as send it to the arduino on the car.
